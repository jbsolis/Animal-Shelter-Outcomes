{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbsol\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train = pd.read_csv(\"clean_train.csv\")\n",
    "c_test = pd.read_csv(\"clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encode(category):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(category)\n",
    "    return integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(data):\n",
    "    data = data.reshape(len(data), 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    data = onehot_encoder.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_train['SexuponOutcome'] = c_train.IsAltered + c_train.Gender\n",
    "c_test['SexuponOutcome'] = c_test.IsAltered + c_test.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select features you want in model\n",
    "wanted_features = ['AnimalType', 'SexuponOutcome', 'HasName', 'Year',\n",
    "                  'Month', 'Day', 'Hour', 'DayofWeek',\n",
    "                  'BreedType', 'CleanAge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = c_test[wanted_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbsol\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\pandas\\core\\generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Encode all categorical data\n",
    "test.AnimalType = label_encode(test.AnimalType)\n",
    "#test.Gender = label_encode(test.Gender)\n",
    "test.HasName = label_encode(test.HasName)\n",
    "#test.IsAltered = label_encode(test.IsAltered)\n",
    "test.BreedType = label_encode(test.BreedType)\n",
    "test.SexuponOutcome = label_encode(test.SexuponOutcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbsol\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\pandas\\core\\generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "test.CleanAge = np.log(test.CleanAge+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate labels from features.  Delete OutcomeSubtype\n",
    "labels = c_train.OutcomeType\n",
    "features = c_train[wanted_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>BreedType</th>\n",
       "      <th>CleanAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>AlteredMale</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>AlteredFemale</td>\n",
       "      <td>True</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>AlteredMale</td>\n",
       "      <td>True</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat</td>\n",
       "      <td>IntactMale</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>AlteredMale</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Full Breed</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalType SexuponOutcome  HasName  Year  Month  Day  Hour  DayofWeek  \\\n",
       "0        Dog    AlteredMale     True  2014      2   12    18          2   \n",
       "1        Cat  AlteredFemale     True  2013     10   13    12          6   \n",
       "2        Dog    AlteredMale     True  2015      1   31    12          5   \n",
       "3        Cat     IntactMale    False  2014      7   11    19          4   \n",
       "4        Dog    AlteredMale    False  2013     11   15    12          4   \n",
       "\n",
       "     BreedType  CleanAge  \n",
       "0  Mixed Breed  1.000000  \n",
       "1  Mixed Breed  1.000000  \n",
       "2  Mixed Breed  2.000000  \n",
       "3  Mixed Breed  0.057692  \n",
       "4   Full Breed  2.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = label_encode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbsol\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\pandas\\core\\generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "features.AnimalType = label_encode(features.AnimalType)\n",
    "#features.Gender = label_encode(features.Gender)\n",
    "features.HasName = label_encode(features.HasName)\n",
    "#features.IsAltered = label_encode(features.IsAltered)\n",
    "features.BreedType = label_encode(features.BreedType)\n",
    "features.SexuponOutcome = label_encode(features.SexuponOutcome)\n",
    "features.CleanAge = np.log(features.CleanAge + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved pickle\n",
      "{'LR__C': 10, 'SKB__k': 8}\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k=8, score_func=<function f_classif at 0x000001E735044A60>)), ('LR', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1123, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# Run model if it exists\n",
    "try:\n",
    "    classifier_f = open(\"bag_log_reg.pickle\", \"rb\")\n",
    "    classifier = pickle.load(classifier_f)\n",
    "    classifier_f.close()\n",
    "    lrclf = classifier.best_estimator_\n",
    "    print(classifier.best_params_)\n",
    "    print(lrclf)\n",
    "    \n",
    "except OSError:\n",
    "    logreg = LogisticRegression(random_state = 1123)\n",
    "    skb = SelectKBest(f_classif)\n",
    "\n",
    "    pipeline = Pipeline(steps=[(\"SKB\",skb),\n",
    "                                   (\"LR\", logreg)])\n",
    "\n",
    "    params = {'SKB__k':[8],\n",
    "              'LR__C': [10]}\n",
    "\n",
    "    split = StratifiedShuffleSplit(labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    gs = GridSearchCV(pipeline, params, cv = split, scoring = 'neg_log_loss')\n",
    "\n",
    "    gs.fit(features,labels)\n",
    "    lrclf=gs.best_estimator_\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    print(lrclf)\n",
    "\n",
    "    save_classifier = open(\"bag_log_reg.pickle\",\"wb\")\n",
    "    pickle.dump(gs, save_classifier)\n",
    "    save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ba_log_reg.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-052e7d36d09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ba_log_reg.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ba_log_reg.pickle'"
     ]
    }
   ],
   "source": [
    "classifier_f = open(\"ba_log_reg.pickle\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.41656881e-01  -1.21501281e+00   7.86560500e-01  -5.52105409e-04\n",
      "    1.43339094e-01   1.32109171e-01  -1.48153667e-01  -1.07357871e+00]\n",
      " [ -3.77037842e-01   5.62389194e-01  -2.03506306e-01  -1.87372245e-03\n",
      "   -1.31677389e-01   2.26124909e-02   6.27904312e-02  -3.07182344e-01]\n",
      " [ -8.44070956e-02   5.39012570e-01  -1.07754509e+00  -1.99095205e-03\n",
      "   -9.89555753e-03  -7.38913216e-02   2.40291817e-01   1.21473149e+00]\n",
      " [  1.50205858e+00   1.29925760e-01   2.08042556e+00  -3.15470151e-03\n",
      "    5.26583388e-02  -6.13907502e-02   1.70084003e-01   9.93103668e-01]\n",
      " [ -4.58192365e-01   6.39040096e-01  -9.09309178e-01   9.36946186e-04\n",
      "   -1.45016381e-01  -7.16371158e-02   5.85664773e-04  -1.75310116e-01]]\n"
     ]
    }
   ],
   "source": [
    "#print(classifier.best_estimator_.named_steps['SKB'].get_support())\n",
    "print(classifier.best_estimator_.named_steps['LR'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RF__min_samples_leaf': 10, 'RF__n_estimators': 500, 'SKB__k': 9}\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k=9, score_func=<function f_classif at 0x000001E735044A60>)), ('RF', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=...n_jobs=1,\n",
      "            oob_score=False, random_state=1122, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    classifier_f = open(\"rf.pickle\", \"rb\")\n",
    "    classifier = pickle.load(classifier_f)\n",
    "    classifier_f.close()\n",
    "    \n",
    "    rfclf = classifier.best_estimator_\n",
    "    print(classifier.best_params_)\n",
    "    print(rfclf)\n",
    "except OSError:\n",
    "    rf = RandomForestClassifier(random_state=1122)\n",
    "    skb = SelectKBest(f_classif)\n",
    "\n",
    "    pipeline = Pipeline(steps=[(\"SKB\",skb),\n",
    "                               (\"RF\", rf)])\n",
    "\n",
    "    params = {'SKB__k':[9],\n",
    "              'RF__n_estimators': [500],\n",
    "              'RF__min_samples_leaf': [10],\n",
    "             }\n",
    "\n",
    "    split = StratifiedShuffleSplit(labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    gs = GridSearchCV(pipeline, params, cv = split, scoring = 'neg_log_loss')\n",
    "\n",
    "    gs.fit(features,labels)\n",
    "    rfclf=gs.best_estimator_\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    print(rfclf)\n",
    "    \n",
    "    save_classifier = open(\"rf.pickle\",\"wb\")\n",
    "    pickle.dump(gs, save_classifier)\n",
    "    save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05166747  0.29776381  0.10191834  0.02387635  0.05247086  0.1473534\n",
      "  0.06065115  0.00744333  0.25685528]\n"
     ]
    }
   ],
   "source": [
    "#print(classifier.best_estimator_.named_steps['SKB'].get_support())\n",
    "print(classifier.best_estimator_.named_steps['RF'].feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SKB__k': 10, 'XGB__max_depth': 7, 'XGB__min_child_weight': 4}\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k=10, score_func=<function f_classif at 0x000001E735044A60>)), ('XGB', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=7, min_child_weight=4, missing=nan, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob',\n",
      "       random_state=1123, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1))])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    classifier_f = open(\"xgb.pickle\", \"rb\")\n",
    "    classifier = pickle.load(classifier_f)\n",
    "    classifier_f.close()\n",
    "    \n",
    "    xgclf = classifier.best_estimator_\n",
    "    print(classifier.best_params_)\n",
    "    print(xgclf)\n",
    "except OSError:\n",
    "    xgbc = XGBClassifier(random_state = 1123)\n",
    "    skb = SelectKBest(f_classif)\n",
    "\n",
    "    pipeline = Pipeline(steps=[(\"SKB\",skb),\n",
    "                               (\"XGB\", xgbc)])\n",
    "\n",
    "    params = {'SKB__k':[10],\n",
    "              'XGB__max_depth': [7],\n",
    "              'XGB__min_child_weight':[4],\n",
    "              #'XGB__gamma':[0.1]\n",
    "             }\n",
    "\n",
    "    split = StratifiedShuffleSplit(labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    gs = GridSearchCV(pipeline, params, cv = split, scoring = 'neg_log_loss')\n",
    "\n",
    "    gs.fit(features,labels)\n",
    "    xgclf=gs.best_estimator_\n",
    "    print(gs.best_params_)\n",
    "    print(gs.best_score_)\n",
    "    print(xgclf)\n",
    "    \n",
    "    save_classifier = open(\"xgb.pickle\",\"wb\")\n",
    "    pickle.dump(gs, save_classifier)\n",
    "    save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04797134  0.05231729  0.03224629  0.06382908  0.13432638  0.19633083\n",
      "  0.17075275  0.11203264  0.01542647  0.17476694]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.best_estimator_.named_steps['XGB'].feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 8.83131413]), 'std_fit_time': array([ 0.27982472]), 'mean_score_time': array([ 0.28456826]), 'std_score_time': array([ 0.09573818]), 'param_SKB__k': masked_array(data = [10],\n",
      "             mask = [False],\n",
      "       fill_value = ?)\n",
      ", 'param_XGB__max_depth': masked_array(data = [7],\n",
      "             mask = [False],\n",
      "       fill_value = ?)\n",
      ", 'param_XGB__min_child_weight': masked_array(data = [4],\n",
      "             mask = [False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'SKB__k': 10, 'XGB__max_depth': 7, 'XGB__min_child_weight': 4}], 'split0_test_score': array([-0.76066293]), 'split1_test_score': array([-0.74394925]), 'split2_test_score': array([-0.74782004]), 'split3_test_score': array([-0.7546434]), 'split4_test_score': array([-0.76771505]), 'split5_test_score': array([-0.74557594]), 'split6_test_score': array([-0.74298598]), 'split7_test_score': array([-0.76266297]), 'split8_test_score': array([-0.75722809]), 'split9_test_score': array([-0.75736355]), 'mean_test_score': array([-0.75406072]), 'std_test_score': array([ 0.00813104]), 'rank_test_score': array([1]), 'split0_train_score': array([-0.62264616]), 'split1_train_score': array([-0.62134079]), 'split2_train_score': array([-0.62818772]), 'split3_train_score': array([-0.62617649]), 'split4_train_score': array([-0.62310859]), 'split5_train_score': array([-0.62929513]), 'split6_train_score': array([-0.63383119]), 'split7_train_score': array([-0.62246435]), 'split8_train_score': array([-0.62445989]), 'split9_train_score': array([-0.62513671]), 'mean_train_score': array([-0.6256647]), 'std_train_score': array([ 0.00364435])}\n"
     ]
    }
   ],
   "source": [
    "results = classifier.cv_results_\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict1 = lrclf.predict_proba(test)\n",
    "predict2 = xgclf.predict_proba(test)\n",
    "predict3 = rfclf.predict_proba(test)\n",
    "final_prediction = (predict3 + predict2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(final_prediction,columns=['Adoption','Died','Euthanasia','Return_to_owner','Transfer'])\n",
    "output.index.names = ['ID']\n",
    "output.index += 1\n",
    "output['ID'] = output.index\n",
    "output.to_csv('predictions.csv', columns = ['ID','Adoption','Died','Euthanasia','Return_to_owner','Transfer'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
